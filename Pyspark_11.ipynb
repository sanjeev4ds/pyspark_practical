{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc5cAjvskW9S",
        "outputId": "2b9ed820-aa6c-47cd-836d-348db04de417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4js\n",
            "  Downloading py4js-0.1.2.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting bottle (from py4js)\n",
            "  Downloading bottle-0.12.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark, py4js\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=2d64b84a0dd57a52c39db4b41539db6162fb47c29812c25710144b054c9771eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "  Building wheel for py4js (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py4js: filename=py4js-0.1.2-py3-none-any.whl size=5573 sha256=a59756b7c16dbbec428a0e9b2f813e2aca7ba072fc78c8cf9ec9776d1a9d434d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/ac/0b/a12e14a0341c39773f23df70bcecdeeacdc553430829e2d1a4\n",
            "Successfully built pyspark py4js\n",
            "Installing collected packages: bottle, pyspark, py4js\n",
            "Successfully installed bottle-0.12.25 py4js-0.1.2 pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4js"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark= SparkSession.builder.appName(\"pyspark_practical_session_3\").getOrCreate()"
      ],
      "metadata": {
        "id": "5Bj3VrD2kcDE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_inferschema = spark.read.format(\"csv\")\\\n",
        ".option(\"header\",\"true\")\\\n",
        ".option(\"inferscehma\",\"true\")\\\n",
        ".load(\"/content/drive/MyDrive/Colab Notebooks/manish_kumar_practicals/data_corrupted_records.csv\")\n",
        "df_inferschema.show()"
      ],
      "metadata": {
        "id": "m22T6CpPKU0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e865903-b15a-40a0-f5f8-1a5edd5f4941"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+------+------------+--------+\n",
            "| id|    name|age|salary|     address| nominee|\n",
            "+---+--------+---+------+------------+--------+\n",
            "|  1|  Manish| 26| 75000|       bihar|nominee1|\n",
            "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
            "|  3|  Pritam| 22|150000|   Bangalore|   India|\n",
            "|  4|Prantosh| 17|200000|     Kolkata|   India|\n",
            "|  5|  Vikash| 31|300000|        NULL|nominee5|\n",
            "+---+--------+---+------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
      ],
      "metadata": {
        "id": "4eFZw17cGgXy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema_df = StructType([\n",
        "    StructField(\"id\", IntegerType(), False),\n",
        "    StructField(\"name\", StringType(), False),\n",
        "    StructField(\"age\",IntegerType(),False),\n",
        "    StructField(\"salary\",IntegerType(),False),\n",
        "    StructField(\"address\", StringType(), False),\n",
        "    StructField(\"nominee\", StringType(), False)\n",
        "])\n",
        "\n",
        "df_with_schema = spark.read.format(\"csv\")\\\n",
        ".option(\"mode\",\"DROPMALFORMED\")\\\n",
        ".option(\"badRecordsPath\",\"/content/drive/MyDrive/Colab Notebooks/manish_kumar_practicals\")\\\n",
        ".option(\"header\",\"true\")\\\n",
        ".schema(schema_df)\\\n",
        ".load(\"/content/drive/MyDrive/Colab Notebooks/manish_kumar_practicals/data_corrupted_records.csv\")\n",
        "\n",
        "df_with_schema.show()"
      ],
      "metadata": {
        "id": "PJgtwViPLXtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207bd825-3628-4519-f5e2-7f437f03746a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+------+------------+--------+\n",
            "| id|  name|age|salary|     address| nominee|\n",
            "+---+------+---+------+------------+--------+\n",
            "|  1|Manish| 26| 75000|       bihar|nominee1|\n",
            "|  2|Nikita| 23|100000|uttarpradesh|nominee2|\n",
            "|  5|Vikash| 31|300000|        NULL|nominee5|\n",
            "+---+------+---+------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_schema.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLgORP3ZD4Fd",
        "outputId": "c67fd843-b083-4f4d-df5a-e22feb758842"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            " |-- address: string (nullable = true)\n",
            " |-- nominee: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_schema.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5epvEtc3ESFO",
        "outputId": "131da68e-2765-4573-d7af-6b08634277e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'name', 'age', 'salary', 'address', 'nominee']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simply access column by passing column name\n",
        "df_with_schema.select(\"name\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMtdEquTEcpz",
        "outputId": "b84442cb-8145-47bf-e5d8-e31f8a5c1d9e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|  Manish|\n",
            "|  Nikita|\n",
            "|  Pritam|\n",
            "|Prantosh|\n",
            "|  Vikash|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "qIEUhDzuGwcz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#access the column by using col and passing column name inside\n",
        "df_with_schema.select(col(\"name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYTn2ldcGuq_",
        "outputId": "44afff2d-9125-474c-89a6-2a69b938e126"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|  Manish|\n",
            "|  Nikita|\n",
            "|  Pritam|\n",
            "|Prantosh|\n",
            "|  Vikash|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#issue comes with passing normal name\n",
        "df_with_schema.select(\"id +5\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "_vtbu_OEG2cX",
        "outputId": "fa06672b-b601-471e-e68c-abe65c07a689"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id +5` cannot be resolved. Did you mean one of the following? [`id`, `age`, `name`, `address`, `salary`].;\n'Project ['id +5]\n+- Relation [id#224,name#225,age#226,salary#227,address#228,nominee#229] csv\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c80374c9676e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#issue comes with passing normal name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_with_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id +5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3227\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3228\u001b[0m         \"\"\"\n\u001b[0;32m-> 3229\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id +5` cannot be resolved. Did you mean one of the following? [`id`, `age`, `name`, `address`, `salary`].;\n'Project ['id +5]\n+- Relation [id#224,name#225,age#226,salary#227,address#228,nominee#229] csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#above error we face as this column is id and \"+ 5\" is not a column name"
      ],
      "metadata": {
        "id": "DMIS43SkHUVX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to avoid above issue we can by pass this with help of col\n",
        "df_with_schema.select(col(\"id\")+5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyqY1UJHHdjD",
        "outputId": "310b6fd2-7921-45f9-8c07-451f2b13b1e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|(id + 5)|\n",
            "+--------+\n",
            "|       6|\n",
            "|       7|\n",
            "|       8|\n",
            "|       9|\n",
            "|      10|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select multiple columns\n",
        "df_with_schema.select(\"id\",\"name\",\"age\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iJ-wmfpHriF",
        "outputId": "251502cd-dd18-422c-f6c2-2d99adea017e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+\n",
            "| id|    name|age|\n",
            "+---+--------+---+\n",
            "|  1|  Manish| 26|\n",
            "|  2|  Nikita| 23|\n",
            "|  3|  Pritam| 22|\n",
            "|  4|Prantosh| 17|\n",
            "|  5|  Vikash| 31|\n",
            "+---+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select multiple columns through cols,\n",
        "#but avoid using this when we just want to access columns, use single string approach only\n",
        "df_with_schema.select(col(\"id\"),col(\"name\"),col(\"age\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSmBemCqH8cr",
        "outputId": "dd1f9735-a1cd-49d6-dc54-2704bc9eb9b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+\n",
            "| id|    name|age|\n",
            "+---+--------+---+\n",
            "|  1|  Manish| 26|\n",
            "|  2|  Nikita| 23|\n",
            "|  3|  Pritam| 22|\n",
            "|  4|Prantosh| 17|\n",
            "|  5|  Vikash| 31|\n",
            "+---+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiple approaches all at once\n",
        "#string approach\n",
        "#col approach\n",
        "#passing col name in [\"\"] like pandas\n",
        "#retreiving column like in sql i.e: .column_name\n",
        "\n",
        "df_with_schema.select(\n",
        "    \"id\",\n",
        "    col(\"name\"),\n",
        "    df_with_schema[\"age\"],\n",
        "    df_with_schema.salary\n",
        ").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxKOllHVIBaZ",
        "outputId": "b259e6f9-c4db-4ef3-d61a-a2b815c00daa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+------+\n",
            "| id|    name|age|salary|\n",
            "+---+--------+---+------+\n",
            "|  1|  Manish| 26| 75000|\n",
            "|  2|  Nikita| 23|100000|\n",
            "|  3|  Pritam| 22|150000|\n",
            "|  4|Prantosh| 17|200000|\n",
            "|  5|  Vikash| 31|300000|\n",
            "+---+--------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_name.column_name used in joins specially"
      ],
      "metadata": {
        "id": "jXnUCErPI689"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution for below issue\n",
        "\n",
        "#issue comes with passing normal name\n",
        "#code--> df_with_schema.select(\"id +5\").show()\n",
        "\n",
        "#solution will be with help of expressions\n",
        "\n",
        "df_with_schema.select(expr(\"id +5\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xyTdLZBJIJy",
        "outputId": "93587290-f7e2-445a-f234-6a5e7fa2f9f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|(id + 5)|\n",
            "+--------+\n",
            "|       6|\n",
            "|       7|\n",
            "|       8|\n",
            "|       9|\n",
            "|      10|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#helps in aliasing\n",
        "\n",
        "df_with_schema.select(expr(\"id as employee_id\"), expr(\"name as employee_name\"), expr(\"concat(name,address)\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qit5y5MtJOBv",
        "outputId": "ee241ce4-4935-4a07-966f-32cfcf26023a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+---------------------+\n",
            "|employee_id|employee_name|concat(name, address)|\n",
            "+-----------+-------------+---------------------+\n",
            "|          1|       Manish|          Manishbihar|\n",
            "|          2|       Nikita|   Nikitauttarpradesh|\n",
            "|          3|       Pritam|      PritamBangalore|\n",
            "|          4|     Prantosh|      PrantoshKolkata|\n",
            "|          5|       Vikash|                 NULL|\n",
            "+-----------+-------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how to write same code in spark sql\n",
        "\n",
        "#convert df to temporary view table"
      ],
      "metadata": {
        "id": "k5wmKo-4MbS8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_schema.createOrReplaceTempView(\"df_with_schema_tbl\")"
      ],
      "metadata": {
        "id": "UUgW4RD9MhuK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "select * from df_with_schema_tbl\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YrAFyXLMsI5",
        "outputId": "1da8e773-1c54-4319-c347-e687b6ab78af"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+------+------------+--------+\n",
            "| id|  name|age|salary|     address| nominee|\n",
            "+---+------+---+------+------------+--------+\n",
            "|  1|Manish| 26| 75000|       bihar|nominee1|\n",
            "|  2|Nikita| 23|100000|uttarpradesh|nominee2|\n",
            "|  5|Vikash| 31|300000|        NULL|nominee5|\n",
            "+---+------+---+------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "select id, name, salary from df_with_schema_tbl\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcN-GW-LNAV8",
        "outputId": "bfbf8cef-1f29-4eec-d242-317e1693c703"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+\n",
            "| id|    name|salary|\n",
            "+---+--------+------+\n",
            "|  1|  Manish| 75000|\n",
            "|  2|  Nikita|100000|\n",
            "|  3|  Pritam|150000|\n",
            "|  4|Prantosh|200000|\n",
            "|  5|  Vikash|300000|\n",
            "+---+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly in dataframe also we can select all columns\n",
        "df_with_schema.select(\"*\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTzi1bMyMyKd",
        "outputId": "9f4a8ca4-78b2-4579-d1ae-c6a3cd2ffb7d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+------+------------+--------+\n",
            "| id|  name|age|salary|     address| nominee|\n",
            "+---+------+---+------+------------+--------+\n",
            "|  1|Manish| 26| 75000|       bihar|nominee1|\n",
            "|  2|Nikita| 23|100000|uttarpradesh|nominee2|\n",
            "|  5|Vikash| 31|300000|        NULL|nominee5|\n",
            "+---+------+---+------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38NQq_W2M9Ou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}